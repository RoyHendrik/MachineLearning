{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e187f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# Gaat het regenen of niet?\n",
    "\n",
    "# TG        = Etmaalgemiddelde temperatuur (in 0.1 graden Celsius)\n",
    "# FG        = Etmaalgemiddelde windsnelheid (in 0.1 m/s)\n",
    "# UG        = Etmaalgemiddelde relatieve vochtigheid (in procenten)\n",
    "# PG        = Etmaalgemiddelde luchtdruk herleid tot zeeniveau (in 0.1 hPa) berekend uit 24 uurwaarden\n",
    "# RH        = Etmaalsom van de neerslag (in 0.1 mm) (-1 voor <0.05 mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23779ad5",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 TG            FG            UG            PG            RH\n",
       "count  23825.000000  23824.000000  16559.000000  23829.000000  23829.000000\n",
       "mean      99.013305     50.969862     82.332448  10150.417433      0.673885\n",
       "std       59.214849     25.524074      8.557631     99.687823      0.468800\n",
       "min     -122.000000      0.000000     35.000000   9614.000000      0.000000\n",
       "25%       58.000000     31.000000     77.000000  10091.000000      0.000000\n",
       "50%      100.000000     46.000000     83.000000  10157.000000      1.000000\n",
       "75%      147.000000     67.000000     89.000000  10217.000000      1.000000\n",
       "max      265.000000    195.000000    100.000000  10459.000000      1.000000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TG</th>\n      <th>FG</th>\n      <th>UG</th>\n      <th>PG</th>\n      <th>RH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>23825.000000</td>\n      <td>23824.000000</td>\n      <td>16559.000000</td>\n      <td>23829.000000</td>\n      <td>23829.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>99.013305</td>\n      <td>50.969862</td>\n      <td>82.332448</td>\n      <td>10150.417433</td>\n      <td>0.673885</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>59.214849</td>\n      <td>25.524074</td>\n      <td>8.557631</td>\n      <td>99.687823</td>\n      <td>0.468800</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-122.000000</td>\n      <td>0.000000</td>\n      <td>35.000000</td>\n      <td>9614.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>58.000000</td>\n      <td>31.000000</td>\n      <td>77.000000</td>\n      <td>10091.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>100.000000</td>\n      <td>46.000000</td>\n      <td>83.000000</td>\n      <td>10157.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>147.000000</td>\n      <td>67.000000</td>\n      <td>89.000000</td>\n      <td>10217.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>265.000000</td>\n      <td>195.000000</td>\n      <td>100.000000</td>\n      <td>10459.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# import data\n",
    "tempdf = pd.read_csv('Data.txt', low_memory=False)\n",
    "tempdf['TG'] = pd.to_numeric(tempdf['TG'], errors='coerce')\n",
    "tempdf['FG'] = pd.to_numeric(tempdf['FG'], errors='coerce')\n",
    "tempdf['UG'] = pd.to_numeric(tempdf['UG'], errors='coerce')\n",
    "tempdf['PG'] = pd.to_numeric(tempdf['PG'], errors='coerce')\n",
    "tempdf['RH'] = pd.to_numeric(tempdf['RH'], errors='coerce')\n",
    "\n",
    "df = tempdf[['TG','FG','UG','PG','RH']].dropna(how='all')\n",
    "\n",
    "# ik heb gekozen om RH om te zetten naar 0 of 1. bij 0 regent het niet, bij 1 regent het wel.\n",
    "df['RH'] = np.where(df['RH']<= 0, 0 ,1)\n",
    "\n",
    "# deze df sla ik op om later de orginele waardes nog te kunnen gebruiken\n",
    "originaldf = df\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7abd0ca3",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 TG            FG            UG            PG            RH\n",
       "count  2.382900e+04  2.382900e+04  2.382900e+04  2.382900e+04  2.382900e+04\n",
       "mean   2.385472e-17 -1.526702e-16 -1.561292e-15  2.972298e-15 -1.908378e-17\n",
       "std    1.000021e+00  1.000021e+00  1.000021e+00  1.000021e+00  1.000021e+00\n",
       "min   -3.732788e+00 -1.997184e+00 -6.635205e+00 -5.381085e+00 -1.437498e+00\n",
       "25%   -6.926913e-01 -7.824917e-01 -3.269695e-01 -5.960475e-01 -1.437498e+00\n",
       "50%    1.666471e-02 -1.947373e-01 -1.992120e-15  6.603320e-02  6.956531e-01\n",
       "75%    8.104678e-01  6.281190e-01  5.141286e-01  6.679248e-01  6.956531e-01\n",
       "max    2.803420e+00  5.643624e+00  2.476691e+00  3.095554e+00  6.956531e-01"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TG</th>\n      <th>FG</th>\n      <th>UG</th>\n      <th>PG</th>\n      <th>RH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2.382900e+04</td>\n      <td>2.382900e+04</td>\n      <td>2.382900e+04</td>\n      <td>2.382900e+04</td>\n      <td>2.382900e+04</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.385472e-17</td>\n      <td>-1.526702e-16</td>\n      <td>-1.561292e-15</td>\n      <td>2.972298e-15</td>\n      <td>-1.908378e-17</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.000021e+00</td>\n      <td>1.000021e+00</td>\n      <td>1.000021e+00</td>\n      <td>1.000021e+00</td>\n      <td>1.000021e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-3.732788e+00</td>\n      <td>-1.997184e+00</td>\n      <td>-6.635205e+00</td>\n      <td>-5.381085e+00</td>\n      <td>-1.437498e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-6.926913e-01</td>\n      <td>-7.824917e-01</td>\n      <td>-3.269695e-01</td>\n      <td>-5.960475e-01</td>\n      <td>-1.437498e+00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.666471e-02</td>\n      <td>-1.947373e-01</td>\n      <td>-1.992120e-15</td>\n      <td>6.603320e-02</td>\n      <td>6.956531e-01</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>8.104678e-01</td>\n      <td>6.281190e-01</td>\n      <td>5.141286e-01</td>\n      <td>6.679248e-01</td>\n      <td>6.956531e-01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.803420e+00</td>\n      <td>5.643624e+00</td>\n      <td>2.476691e+00</td>\n      <td>3.095554e+00</td>\n      <td>6.956531e-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Data cleanup\n",
    "df['UG'] = df ['UG'].replace('     ',df['UG'].mean())\n",
    "df['RH'] = df ['RH'].replace('     ',df['RH'].mean())\n",
    "\n",
    "# ik heb gekozen om de null waardes te vervangen voor een gemiddelde omdat ik niet de gehele row wil laten vallen. \n",
    "# Aangezien daar veel bruikbare data in zit.\n",
    "df['TG'] = df ['TG'].fillna(df['TG'].mean())\n",
    "df['FG'] = df ['FG'].fillna(df['FG'].mean())\n",
    "df['UG'] = df ['UG'].fillna(df['UG'].mean())\n",
    "df['RH'] = df ['RH'].fillna(df['UG'].mean())\n",
    "\n",
    "# normaliseren van de data\n",
    "df_s = preprocessing.scale(df)\n",
    "df_s = pd.DataFrame(df_s, columns = df.columns)\n",
    "df = df_s\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05087f42",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0        1\n1        1\n2        1\n3        1\n4        1\n        ..\n23859    1\n23860    1\n23861    0\n23862    0\n23863    1\nName: RH, Length: 23829, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# split test and train data\n",
    "X = df.drop(columns=['RH'])\n",
    "\n",
    "# de y geef ik de 'orginele' waarde mee. deze bestaat uit 0 of 1.\n",
    "y = originaldf['RH']\n",
    "\n",
    "print(y)\n",
    "# Ik heb gekozen voor een kleine test size omdat er veel data is.\n",
    "# En omdat ik het trainen belangrijker vind dan het vergelijken van de test en train data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ff886e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "671/671 [==============================] - 23s 1ms/step - loss: 0.5443 - accuracy: 0.7316\n",
      "Epoch 2/100\n",
      "671/671 [==============================] - 1s 1ms/step - loss: 0.4601 - accuracy: 0.7912\n",
      "Epoch 3/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.4337 - accuracy: 0.7996\n",
      "Epoch 4/100\n",
      "671/671 [==============================] - 1s 1ms/step - loss: 0.4246 - accuracy: 0.8067\n",
      "Epoch 5/100\n",
      "671/671 [==============================] - 1s 1ms/step - loss: 0.4093 - accuracy: 0.8093\n",
      "Epoch 6/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.4046 - accuracy: 0.8081\n",
      "Epoch 7/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3882 - accuracy: 0.8201\n",
      "Epoch 8/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3919 - accuracy: 0.8153\n",
      "Epoch 9/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3887 - accuracy: 0.8156\n",
      "Epoch 10/100\n",
      "671/671 [==============================] - 2s 4ms/step - loss: 0.3805 - accuracy: 0.8184\n",
      "Epoch 11/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3780 - accuracy: 0.8207\n",
      "Epoch 12/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3774 - accuracy: 0.8191\n",
      "Epoch 13/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3698 - accuracy: 0.8196\n",
      "Epoch 14/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3693 - accuracy: 0.8239\n",
      "Epoch 15/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3698 - accuracy: 0.8189\n",
      "Epoch 16/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3608 - accuracy: 0.8233\n",
      "Epoch 17/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3668 - accuracy: 0.8187\n",
      "Epoch 18/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3549 - accuracy: 0.8235\n",
      "Epoch 19/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8264\n",
      "Epoch 20/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3483 - accuracy: 0.8269\n",
      "Epoch 21/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3535 - accuracy: 0.8252\n",
      "Epoch 22/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3548 - accuracy: 0.8233\n",
      "Epoch 23/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3531 - accuracy: 0.8270\n",
      "Epoch 24/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3520 - accuracy: 0.8262\n",
      "Epoch 25/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8275\n",
      "Epoch 26/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3517 - accuracy: 0.8235\n",
      "Epoch 27/100\n",
      "671/671 [==============================] - 4s 5ms/step - loss: 0.3484 - accuracy: 0.8271\n",
      "Epoch 28/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3485 - accuracy: 0.8290\n",
      "Epoch 29/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3507 - accuracy: 0.8280\n",
      "Epoch 30/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3500 - accuracy: 0.8272\n",
      "Epoch 31/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8315\n",
      "Epoch 32/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3500 - accuracy: 0.8268\n",
      "Epoch 33/100\n",
      "671/671 [==============================] - 2s 4ms/step - loss: 0.3484 - accuracy: 0.8251\n",
      "Epoch 34/100\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.3494 - accuracy: 0.8252\n",
      "Epoch 35/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8284\n",
      "Epoch 36/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3499 - accuracy: 0.8289\n",
      "Epoch 37/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3489 - accuracy: 0.8246\n",
      "Epoch 38/100\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.3458 - accuracy: 0.8314\n",
      "Epoch 39/100\n",
      "671/671 [==============================] - 6s 8ms/step - loss: 0.3448 - accuracy: 0.8277\n",
      "Epoch 40/100\n",
      "671/671 [==============================] - 6s 9ms/step - loss: 0.3513 - accuracy: 0.8269\n",
      "Epoch 41/100\n",
      "671/671 [==============================] - 5s 7ms/step - loss: 0.3483 - accuracy: 0.8270\n",
      "Epoch 42/100\n",
      "671/671 [==============================] - 2s 4ms/step - loss: 0.3509 - accuracy: 0.8237\n",
      "Epoch 43/100\n",
      "671/671 [==============================] - 3s 4ms/step - loss: 0.3416 - accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3463 - accuracy: 0.8264\n",
      "Epoch 45/100\n",
      "671/671 [==============================] - 2s 2ms/step - loss: 0.3512 - accuracy: 0.8234\n",
      "Epoch 46/100\n",
      "671/671 [==============================] - 2s 2ms/step - loss: 0.3450 - accuracy: 0.8295\n",
      "Epoch 47/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3454 - accuracy: 0.8311\n",
      "Epoch 48/100\n",
      "671/671 [==============================] - 2s 2ms/step - loss: 0.3510 - accuracy: 0.8260\n",
      "Epoch 49/100\n",
      "671/671 [==============================] - 2s 4ms/step - loss: 0.3446 - accuracy: 0.8280\n",
      "Epoch 50/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3433 - accuracy: 0.8327\n",
      "Epoch 51/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3443 - accuracy: 0.8296\n",
      "Epoch 52/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3450 - accuracy: 0.8282\n",
      "Epoch 53/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3486 - accuracy: 0.8259\n",
      "Epoch 54/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3454 - accuracy: 0.8290\n",
      "Epoch 55/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3530 - accuracy: 0.8240\n",
      "Epoch 56/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3395 - accuracy: 0.8295\n",
      "Epoch 57/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3476 - accuracy: 0.8288\n",
      "Epoch 58/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3482 - accuracy: 0.8293\n",
      "Epoch 59/100\n",
      "671/671 [==============================] - 2s 2ms/step - loss: 0.3481 - accuracy: 0.8289\n",
      "Epoch 60/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3474 - accuracy: 0.8263\n",
      "Epoch 61/100\n",
      "671/671 [==============================] - 2s 4ms/step - loss: 0.3494 - accuracy: 0.8263\n",
      "Epoch 62/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3520 - accuracy: 0.8228\n",
      "Epoch 63/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3432 - accuracy: 0.8290\n",
      "Epoch 64/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3410 - accuracy: 0.8367\n",
      "Epoch 65/100\n",
      "671/671 [==============================] - 2s 2ms/step - loss: 0.3431 - accuracy: 0.8295\n",
      "Epoch 66/100\n",
      "671/671 [==============================] - 2s 2ms/step - loss: 0.3445 - accuracy: 0.8276\n",
      "Epoch 67/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3420 - accuracy: 0.8300\n",
      "Epoch 68/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3436 - accuracy: 0.8294\n",
      "Epoch 69/100\n",
      "671/671 [==============================] - 2s 2ms/step - loss: 0.3445 - accuracy: 0.8277\n",
      "Epoch 70/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3438 - accuracy: 0.8291\n",
      "Epoch 71/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3516 - accuracy: 0.8231\n",
      "Epoch 72/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8279\n",
      "Epoch 73/100\n",
      "671/671 [==============================] - 1s 1ms/step - loss: 0.3438 - accuracy: 0.8272\n",
      "Epoch 74/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3406 - accuracy: 0.8295\n",
      "Epoch 75/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3415 - accuracy: 0.8335\n",
      "Epoch 76/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3502 - accuracy: 0.8279\n",
      "Epoch 77/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3472 - accuracy: 0.8254\n",
      "Epoch 78/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3407 - accuracy: 0.8318\n",
      "Epoch 79/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3437 - accuracy: 0.8314\n",
      "Epoch 80/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3407 - accuracy: 0.8308\n",
      "Epoch 81/100\n",
      "671/671 [==============================] - 2s 2ms/step - loss: 0.3386 - accuracy: 0.8310\n",
      "Epoch 82/100\n",
      "671/671 [==============================] - 2s 2ms/step - loss: 0.3435 - accuracy: 0.8285\n",
      "Epoch 83/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3463 - accuracy: 0.8242\n",
      "Epoch 84/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3451 - accuracy: 0.8254\n",
      "Epoch 85/100\n",
      "671/671 [==============================] - 2s 2ms/step - loss: 0.3496 - accuracy: 0.8253\n",
      "Epoch 86/100\n",
      "671/671 [==============================] - 3s 4ms/step - loss: 0.3480 - accuracy: 0.8256\n",
      "Epoch 87/100\n",
      "671/671 [==============================] - 3s 4ms/step - loss: 0.3377 - accuracy: 0.8335\n",
      "Epoch 88/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8251\n",
      "Epoch 89/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8274\n",
      "Epoch 90/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3469 - accuracy: 0.8301\n",
      "Epoch 91/100\n",
      "671/671 [==============================] - 2s 2ms/step - loss: 0.3390 - accuracy: 0.8314\n",
      "Epoch 92/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8300\n",
      "Epoch 93/100\n",
      "671/671 [==============================] - 2s 3ms/step - loss: 0.3462 - accuracy: 0.8286\n",
      "Epoch 94/100\n",
      "671/671 [==============================] - 2s 2ms/step - loss: 0.3431 - accuracy: 0.8319\n",
      "Epoch 95/100\n",
      "671/671 [==============================] - 1s 1ms/step - loss: 0.3458 - accuracy: 0.8300\n",
      "Epoch 96/100\n",
      "671/671 [==============================] - 1s 1ms/step - loss: 0.3492 - accuracy: 0.8264\n",
      "Epoch 97/100\n",
      "671/671 [==============================] - 1s 1ms/step - loss: 0.3438 - accuracy: 0.8280\n",
      "Epoch 98/100\n",
      "671/671 [==============================] - 1s 2ms/step - loss: 0.3474 - accuracy: 0.8287\n",
      "Epoch 99/100\n",
      "671/671 [==============================] - 1s 1ms/step - loss: 0.3475 - accuracy: 0.8233\n",
      "Epoch 100/100\n",
      "671/671 [==============================] - 1s 1ms/step - loss: 0.3432 - accuracy: 0.8305\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c6b46c1070>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# setup en train model\n",
    "model = Sequential()\n",
    "\n",
    "# Ik heb gezien dat er van 50 naar 100 itteraties er WEINIG verbetering is in accuracy, bij het gebruik van dense 16, 8.\n",
    "# epoch 1 - accuracy: 0.7121\n",
    "# epoch 50 - accuracy: 0.8289\n",
    "# epoch 100 - accuracy: 0.8316\n",
    "\n",
    "# Ik heb gezien dat er vanaf 50 itteraties GEEN verbetering is in accuracy, bij het gebruik van dense 32, 16.\n",
    "# Wat opvalt is dat er wel vanaf epoch 1 een hogere accuracy is in vergelijking tot een dense van 16, 8. \n",
    "# epoch 1 - accuracy: 0.7304\n",
    "# epoch 50 - accuracy: 0.8328\n",
    "# epoch 100 - accuracy: 0.8291\n",
    "\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_dim=4))\n",
    "model.add(Dense(16, activation='relu', input_dim=4))\n",
    "\n",
    "# Ik heb helaas geen wiskunde gestudeerd en zou niet kunnen uitleggen waarom sigmoid een goede keuzes is voor dit project.\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Voor zo ver ik het gebrijp gebruik je Cross entropy om de berekenen hoeveel twee waarden van elkaar af liggen.\n",
    "# In dit geval redeneer ik dat het gaat om de Binary afstand.\n",
    "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy']  )\n",
    "\n",
    "# train het model\n",
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "903fa396",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "75/75 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8372\n"
     ]
    }
   ],
   "source": [
    "# test het model\n",
    "score_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "053aadea",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\mrjor\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "[[1]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# vraag het netwerk om een voorspelling te doen. Gaat het regenen of niet?\n",
    "# normale waardes van:\n",
    "# TG tussen de  -122 en de 265.    -Met normalisatie  -3.72 / 2.80\n",
    "# FG tussen de  0 en de 195.       -Met normalisatie  -1.99 / 5.64\n",
    "# UG tussen de  35 en de 100.      -Met normalisatie  -6.64 / 2.48\n",
    "# PG tussen de  9614 en de 10459.  -Met normalisatie  -5.38 / 3.10\n",
    "\n",
    "# RH tussen de  -1 en de 675.  <== deze hoef je dus niet op te geven.\n",
    "\n",
    "# geef het in deze volgorde op in de array: TG FG UG PG\n",
    "# [[67,118,91,10128]]  op deze dag regende het. YYYYMMDD : 19751231\n",
    "# [[65,67,89, 10282]]  op deze dag regende het niet YYYYMMDD : 19751227\n",
    "\n",
    "X = [[67,118,91,10128]]\n",
    "\n",
    "#dit heb ik nog niet werkend gkregen.\n",
    "Xn = preprocessing.scale(X)\n",
    "\n",
    "print(model.predict_classes(Xn))\n",
    "#print(np.argmax(model.predict(Xn), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb0088e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python394jvsc74a57bd0475876959fa4f7cf9bb8a50714baed7cfda638ac9a9c494febd2211c6dc6c1fb",
   "display_name": "Python 3.9.4 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}